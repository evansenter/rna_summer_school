Learning is essential for building intelligent systems, whether carbon-based or silicon-based ones. Moreover these systems do not solve complex tasks in a single step but rather go through multiple processing stages. Hence the question of deep learning, how efficient learning can be implemented in deep architectures. This fundamental question not only impinges on problems of memory and intelligence in the brain, but it is also at the forefront of current machine learning research. In the last year alone, new performance breakthroughs have been achieved by deep learning methods in applications areas ranging from computer vision, to speech recognition, to natural language understanding, to bioinformatics. This talk will provide a brief overview of deep learning, from its biological origins to some of the latest theoretical, algorithmic, and application results. Particular emphasis will be given to the development of learning methods--in the form of recursive neural networks-- for structured, variable-size, data, and their applications to the problems of predicting the properties of small molecules and the structure of proteins.
